大量特征包括相关特征和不相关特征, 需要做特征工程, 进行特征选择.

1. 选择N个特征
2. 交给XGboost和RandomForest 跑 得到特征重要性 一般选择gini增益, 来排序特征
3. 数值预测, 用xgboost加入 lambda进行变量筛选
4. 剔除特征, 重新fit



validation curve 验证曲线

dimensions 维度

hyperparameter 超参数

confusion matrix 混淆矩阵

threshold 阈值

precision 精确率

recall 召回率





### 数据处理流程

- 数据获取
- 整理数据
- 注释数据
- 总结数据
- 数据可视化
- 数据建模
- 整理结果

### R的行 observation 列 variable

### 常用函数

- length()
- dim() 显示维度
- str() 显示结构
- class() 类型
- names() 各成分名称
- c() 将对象合并入一个向量
- cbind() 按列合并
- rbind() 按行合并
- head() 开始部分
- tail() 最后部分
- ls() 当前对象列表

### 类型转换

- as.numeric()
- as.character()
- as.vector()
- as.matrix()
- as.dataframe()
- as.factor()
- as.logical()

### 排序

order() 

```R
newdata <- leadership[order(gender, -age)]
```

### 数据集取子集

subset()



使用随机森林回归器计算出特征重要性

根据这几个特征, 对数据做出筛选

对数据建模 进行预测

逻辑回归(二分类 F1得分) 岭回归 lasso回归 随机森林分类(交叉验证得分→通过网格曲线调整参数  分类报告)

### 全基因组测序检测早期癌症(肿瘤和非肿瘤)

对546例CRC患者和271例正常者中的DNA进行全基因组测序

数据进行归一化

ML模型评估使用K折交叉验证 CV 来评估泛化性能

AUC 0.92 (95%CI 0.91-0.93)



归一化: 每个样本的每个特征值/该样本各个特征值的总和

正则化:限制模型参数值 不要过大 也称惩罚项

参数:L1 绝对值之和 → 特征稀疏化 易变为0

L2平方之和 →参数减小到很小的范围 不为0 在回归问题为岭回归



对特征向量预处理 :去除质量差的特征 标准化

影响因素

平衡样本(分组训练)

降维

监督分类算法

K折交叉验证评估



1. 标准化做法

2. SVD和PCA 降维变换

3. LR和SVM超参数
4. 选择最优的超参数
5. LR有两个 1/C 正则强度倒数 L1或L2
6. SVM有三个 1/C 停止容忍准则 径向基核函数的带宽

训练样本少 导致性能下降 → 下采样, 扩充数据集

混淆变量作为输入来训练模型(唯一输入)

对每个影响因素进行独立验证 看AUC的性能

敏感性tpr 预测C/C

特异性(1-fpr) 预测N/N



### 知识点

标准差 均值 中间值 CV(标准差/均值)

两组数据的相关性 pearson kendall spearman

T检验(Ttest) 方差检验(Anova Test)

fold change(fc) 差异倍数(组1均值/组2均值)

p-value 差异的显著性



逻辑回归预测模型

生成期预测模型

时间预测预测模型



Lowess 局部加权回归

z-score

Quantile Normalization 分位数归一化 (正态分布平滑处理)





















